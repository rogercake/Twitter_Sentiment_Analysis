{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe1e137",
   "metadata": {},
   "source": [
    "# Model Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979183d",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4492c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ce58e",
   "metadata": {},
   "source": [
    "### Importing Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a936f6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_clean_tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26505</th>\n",
       "      <td>sad modijiyou complet oblivi pain suffer commo...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>counter shahid social front environ protect mi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84307</th>\n",
       "      <td>yup loo elect buzz zing gone mani vika thingi ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38681</th>\n",
       "      <td>noth desper congress comeback power save caree...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68434</th>\n",
       "      <td>actual funni thing first time voter didnt know...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         new_clean_tweet  category\n",
       "26505  sad modijiyou complet oblivi pain suffer commo...      -1.0\n",
       "21586  counter shahid social front environ protect mi...       1.0\n",
       "84307  yup loo elect buzz zing gone mani vika thingi ...       1.0\n",
       "38681  noth desper congress comeback power save caree...       1.0\n",
       "68434  actual funni thing first time voter didnt know...       1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_cleaned_data.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88d5852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162897, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e5d263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_clean_tweet    2\n",
       "category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc950046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e94b35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_clean_tweet    0\n",
       "category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b5bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162895, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0cbe2",
   "metadata": {},
   "source": [
    "### Separating out train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fd8b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df19d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X ad Y splitting\n",
    "X = df['new_clean_tweet']\n",
    "Y = df['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab57d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=43, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e210faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122171,), (40724,), (122171,), (40724,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6d39f",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea146a",
   "metadata": {},
   "source": [
    "### 1. Training model using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fcad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "nb_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "55fb0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0607ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.90      0.12      0.21      8877\n",
      "         0.0       0.83      0.33      0.47     13786\n",
      "         1.0       0.51      0.97      0.67     18061\n",
      "\n",
      "    accuracy                           0.57     40724\n",
      "   macro avg       0.75      0.47      0.45     40724\n",
      "weighted avg       0.71      0.57      0.50     40724\n",
      "\n",
      "**************************************************\n",
      "[[ 1042   464  7371]\n",
      " [   82  4494  9210]\n",
      " [   36   445 17580]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('*'*50)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c45789",
   "metadata": {},
   "source": [
    "### 2. Training model using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "942ae70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('model',MultinomialNB()), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7685e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nb_model = npipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f83abc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = count_nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e446347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.70      0.56      0.62      8877\n",
      "         0.0       0.81      0.56      0.66     13786\n",
      "         1.0       0.66      0.87      0.75     18061\n",
      "\n",
      "    accuracy                           0.70     40724\n",
      "   macro avg       0.72      0.66      0.68     40724\n",
      "weighted avg       0.71      0.70      0.69     40724\n",
      "\n",
      "**************************************************\n",
      "[[ 4951   785  3141]\n",
      " [  911  7748  5127]\n",
      " [ 1260  1090 15711]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('*'*50)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b196f97",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5fbaedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e038120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('model',LinearSVC()), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32e58690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svm_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b12ed98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f94c3ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.74      0.76      8877\n",
      "         0.0       0.83      0.89      0.86     13786\n",
      "         1.0       0.87      0.85      0.86     18061\n",
      "\n",
      "    accuracy                           0.84     40724\n",
      "   macro avg       0.83      0.83      0.83     40724\n",
      "weighted avg       0.84      0.84      0.84     40724\n",
      "\n",
      "**************************************************\n",
      "[[ 6595   993  1289]\n",
      " [  588 12252   946]\n",
      " [ 1184  1579 15298]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('*'*50)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b813d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f40278d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a0aeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('model',LogisticRegression(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ecfd0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6382d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "07c72e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.81      0.75      0.78      8877\n",
      "         0.0       0.83      0.91      0.87     13786\n",
      "         1.0       0.89      0.85      0.87     18061\n",
      "\n",
      "    accuracy                           0.85     40724\n",
      "   macro avg       0.84      0.84      0.84     40724\n",
      "weighted avg       0.85      0.85      0.85     40724\n",
      "\n",
      "**************************************************\n",
      "[[ 6629  1012  1236]\n",
      " [  439 12591   756]\n",
      " [ 1159  1509 15393]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('*'*50)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac8a39",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de00e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "517a3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=250, max_depth=5, random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "93c25167",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d492f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "65283059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      8877\n",
      "         0.0       0.00      0.00      0.00     13786\n",
      "         1.0       0.44      1.00      0.61     18061\n",
      "\n",
      "    accuracy                           0.44     40724\n",
      "   macro avg       0.15      0.33      0.20     40724\n",
      "weighted avg       0.20      0.44      0.27     40724\n",
      "\n",
      "**************************************************\n",
      "[[    0     0  8877]\n",
      " [    0     0 13786]\n",
      " [    0     0 18061]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('*'*50)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f5c9b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4b374",
   "metadata": {},
   "source": [
    "- After Spot Checking each Classification algorithm we can confirm that SVC classifier is performing best on this dataset becasue of goof F1 score for each category.\n",
    "- Now we will Tune the hyperparameters of SVC classifier to get the best model accuracy for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919f4b6",
   "metadata": {},
   "source": [
    "## Buliding final model to get predection using SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "26bd56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "import os\n",
    "import csv\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import random\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "st_wrds = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a304e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\": \",\"\").split()))\n",
    "    return text\n",
    "\n",
    "#create a function to clean the tweets\n",
    "def clean_text(text):\n",
    "    text = convert_emojis(text) #calling the convert_emojis function to convert all the emojis to text at first place.\n",
    "    text = str(text)\n",
    "    text = text.lower() #converting every words to lowercase\n",
    "    text = re.sub(r'@[A-Za-z0-9_-]+', '', text) #substituing the @user_handle with empty string\n",
    "    text = re.sub(r'#', '', text) #Remove the '#' symbol\n",
    "    text = re.sub(r'RT[\\s]+', '', text) #Removing retweets RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #removing the hyperlink\n",
    "    text = re.sub(r'[0-9]+', '', text) #Removing numbers from the text\n",
    "    \n",
    "    words = word_tokenize(text) #Splitting each words in a sentence\n",
    "    \n",
    "    #use regular expressions to select for the punctuation characters and use the sub() function to replace them with nothing.\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    text = [re_punc.sub('', w) for w in words]\n",
    "    \n",
    "    #removing stop words\n",
    "    text = [word for word in text if not word in st_wrds]\n",
    "    \n",
    "    #removing text with length 1\n",
    "    text = [word for word in text if len(word) > 1 ]\n",
    "      \n",
    "    text = ' '.join([elem for elem in text]) #Converting the whole text into a string\n",
    "    text = re.sub(' +', ' ', text) #Removing extra spaces from the text\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def stem_lem_words(text):\n",
    "    sent = []\n",
    "    for word in text.split():\n",
    "        #Applying Stemming then Applying lemmatization\n",
    "        i = lemma.lemmatize(stemmer.stem(word))\n",
    "        sent.append(i)\n",
    "        \n",
    "    text = ' '.join([elem for elem in sent]) #Converting the whole text into a string\n",
    "    text = re.sub(' +', ' ', text) \n",
    "    return text\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    \n",
    "def preprocess(text):\n",
    "    text = clean_text(text) # First preprocessing the data\n",
    "    text = stem_lem_words(text) #Finally stemming and lemmatizing the words\n",
    "     \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd56c8f",
   "metadata": {},
   "source": [
    "### Function to predict the label of input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6e3c20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_model(text):\n",
    "    text = preprocess(text)\n",
    "    text = [text]\n",
    "    output = svm_model.predict(text)\n",
    "    if output == 0:\n",
    "        print('Neutral')\n",
    "    elif output == 1:\n",
    "        print('Positive')\n",
    "    elif output == -1:\n",
    "        print('Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6dbb4",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "46fd4ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "tweet_model('I will vote for modi 😊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2633f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "tweet_model('Very good work done by BJP here in Lucknow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f4d819e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "tweet_model('very bad behaviour by other party 😡 @narendramodi #stopvoilence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b771c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
